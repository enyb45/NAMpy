import pandas as pd
from sklearn.metrics import mean_squared_error, r2_score
from keras.optimizers import Adam
from nampy.models import NAMLSS
from sklearn.model_selection import train_test_split
from nampy.formulas.formula_utils import*
import pandas as pd
from nampy.visuals.plot_predictions import*
from nampy.formulas.formulas import*
import matplotlib
matplotlib.use('Agg')  # Configuration sp√©cifique pour VS Code
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import os
from scipy import stats

# Configuration sp√©cifique pour VS Code
plt.ion()  # Mode interactif
plt.style.use('default')
sns.set_style("whitegrid")

# Fonction pour sauvegarder les graphiques
def save_plot(name):
    plt.savefig(f'plot_{name}.png')
    plt.close()

# Chargement et pr√©paration des donn√©es
data = pd.read_csv('zambia_height92.raw', sep='\t')
print("SHAPE", data.shape)
X = data.drop(columns=['zscore'])
y = data['zscore']
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Cr√©ation et entra√Ænement du mod√®le
my_formula = all_features_additive_model(df=data, target='zscore', intercept=False)
formula_handler = FormulaHandler()
intercept, y = formula_handler._get_intercept(my_formula)

namlss = NAMLSS(
    formula=my_formula,
    data=data, 
    family="Normal", 
    loss="nll",
)

namlss.compile(
    optimizer=Adam(learning_rate=0.001), 
    loss={"output": namlss.Loss}, 
    metrics={"summed_output": "mse"}
)

# Entra√Ænement
print("Training dataset: ", namlss.training_dataset)
namlss.fit(namlss.training_dataset, epochs=200, validation_data=namlss.validation_dataset)

# √âvaluation
loss = namlss.evaluate(namlss.validation_dataset)
print("Test Loss:", loss)

# Cr√©ation du dossier pour les visualisations
if not os.path.exists('visualisations'):
    os.makedirs('visualisations')

print("\n********************************************")
print("G√©n√©ration des visualisations")
print("********************************************")

# 1. Obtenir les pr√©dictions
preds_all = namlss._get_plotting_preds()
print("\nStructure des pr√©dictions:")
for key, value in preds_all.items():
    if isinstance(value, dict):
        print(f"{key}: dict avec cl√©s {list(value.keys())}")
    else:
        print(f"{key}: array de forme {value.shape}")

# 2. Visualisation des effets de chaque feature
features_to_plot = [(name, preds) for name, preds in preds_all.items() if not isinstance(preds, dict)]
n_features = len(features_to_plot)

# Calculer le nombre de lignes et colonnes n√©cessaires
n_cols = min(3, n_features)
n_rows = (n_features + n_cols - 1) // n_cols

plt.figure(figsize=(5*n_cols, 4*n_rows))
for i, (feature_name, preds) in enumerate(features_to_plot):
    plt.subplot(n_rows, n_cols, i+1)
    plt.plot(preds[:, 0], label='Œº (moyenne)')
    plt.plot(preds[:, 1], label='œÉ (√©cart-type)')
    plt.title(f'Effet de {feature_name}')
    plt.legend()
plt.tight_layout()
plt.savefig('visualisations/effets_features.png')
plt.close()
print(f"Graphique des effets sauvegard√© dans 'visualisations/effets_features.png' ({n_features} features)")

# 3. Distribution des pr√©dictions
preds_dist = namlss.predict(namlss.validation_dataset)["output"]
plt.figure(figsize=(10, 6))
plt.hist(preds_dist, bins=50, density=True, alpha=0.7)
plt.title("Distribution des pr√©dictions")
plt.xlabel("Valeur pr√©dite")
plt.ylabel("Densit√©")
plt.savefig('visualisations/distribution_predictions.png')
plt.close()
print("Distribution sauvegard√©e dans 'visualisations/distribution_predictions.png'")

# 4. Comparaison pr√©dictions vs r√©alit√© - VERSION AM√âLIOR√âE
y_pred = namlss.predict(namlss.validation_dataset)["output"].flatten()  # Aplatir les pr√©dictions
y_val_array = y_val.to_numpy()  # Convertir en array numpy

# Afficher les dimensions pour le d√©bogage
print("\nDimensions des donn√©es :")
print(f"y_pred shape: {y_pred.shape}")
print(f"y_val_array shape: {y_val_array.shape}")

# S'assurer que nous avons le m√™me nombre d'√©chantillons
min_samples = min(len(y_pred), len(y_val_array))
y_pred = y_pred[:min_samples]
y_val_array = y_val_array[:min_samples]

print(f"Apr√®s ajustement - nombre d'√©chantillons utilis√©s: {min_samples}")

# Calculer les erreurs pour l'analyse
errors = y_pred - y_val_array
abs_errors = np.abs(errors)

# Cr√©er une figure avec plusieurs sous-graphiques
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Graphique principal : Pr√©dictions vs R√©alit√©
axes[0, 0].scatter(y_val_array, y_pred, alpha=0.6, s=20)
axes[0, 0].plot([y_val_array.min(), y_val_array.max()], [y_val_array.min(), y_val_array.max()], 'r--', linewidth=2, label='Pr√©diction parfaite')

# Ajouter une zone de tol√©rance adapt√©e √† l'√©chelle r√©elle (¬±50 unit√©s)
tolerance = 50  # Tol√©rance adapt√©e √† l'√©chelle des z-scores (-442 √† +468)
axes[0, 0].fill_between([y_val_array.min(), y_val_array.max()], 
                       [y_val_array.min() - tolerance, y_val_array.max() - tolerance],
                       [y_val_array.min() + tolerance, y_val_array.max() + tolerance],
                       alpha=0.2, color='green', label=f'Zone de tol√©rance (¬±{tolerance})')

axes[0, 0].set_xlabel("Valeurs r√©elles (z-score)")
axes[0, 0].set_ylabel("Valeurs pr√©dites (z-score)")
axes[0, 0].set_title("Comparaison pr√©dictions vs r√©alit√©")
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. Distribution des erreurs
axes[0, 1].hist(errors, bins=30, density=True, alpha=0.7, color='orange')
axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Erreur = 0')
axes[0, 1].set_xlabel("Erreur de pr√©diction")
axes[0, 1].set_ylabel("Densit√©")
axes[0, 1].set_title("Distribution des erreurs")
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. Erreurs absolues vs valeurs r√©elles
axes[1, 0].scatter(y_val_array, abs_errors, alpha=0.6, s=20)
axes[1, 0].set_xlabel("Valeurs r√©elles (z-score)")
axes[1, 0].set_ylabel("Erreur absolue")
axes[1, 0].set_title("Erreurs absolues vs valeurs r√©elles")
axes[1, 0].grid(True, alpha=0.3)

# 4. Graphique Q-Q pour v√©rifier la normalit√© des erreurs
stats.probplot(errors, dist="norm", plot=axes[1, 1])
axes[1, 1].set_title("Graphique Q-Q des erreurs")
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('visualisations/predictions_vs_realite_amelior√©.png', dpi=300, bbox_inches='tight')
plt.close()

# Analyse d√©taill√©e des performances
print("\n" + "="*60)
print("ANALYSE D√âTAILL√âE DES PERFORMANCES DU MOD√àLE")
print("="*60)

mse = mean_squared_error(y_val_array, y_pred)
r2 = r2_score(y_val_array, y_pred)
rmse = np.sqrt(mse)
mae = np.mean(abs_errors)

print(f"\nüìä M√âTRIQUES DE PERFORMANCE:")
print(f"   ‚Ä¢ R¬≤ (Coefficient de d√©termination): {r2:.4f}")
print(f"   ‚Ä¢ RMSE (Racine de l'erreur quadratique moyenne): {rmse:.4f}")
print(f"   ‚Ä¢ MAE (Erreur absolue moyenne): {mae:.4f}")
print(f"   ‚Ä¢ MSE (Erreur quadratique moyenne): {mse:.4f}")

# Analyse des erreurs
print(f"\nüìà ANALYSE DES ERREURS:")
print(f"   ‚Ä¢ Erreur moyenne: {np.mean(errors):.4f}")
print(f"   ‚Ä¢ √âcart-type des erreurs: {np.std(errors):.4f}")
print(f"   ‚Ä¢ Erreur minimale: {np.min(errors):.4f}")
print(f"   ‚Ä¢ Erreur maximale: {np.max(errors):.4f}")

# Pourcentage de pr√©dictions dans la zone de tol√©rance
within_tolerance = np.sum(abs_errors <= tolerance)
percentage_within_tolerance = (within_tolerance / len(errors)) * 100

print(f"\nüéØ PR√âDICTIONS DANS LA ZONE DE TOL√âRANCE (¬±{tolerance}):")
print(f"   ‚Ä¢ {within_tolerance}/{len(errors)} pr√©dictions ({percentage_within_tolerance:.1f}%)")

# Interpr√©tation d√©taill√©e
print(f"\nüîç INTERPR√âTATION:")
if r2 > 0.8:
    print("   ‚úÖ EXCELLENT: Le mod√®le explique plus de 80% de la variance")
    print("   ‚Üí Votre mod√®le est tr√®s performant pour ce type de donn√©es")
elif r2 > 0.6:
    print("   ‚úÖ BON: Le mod√®le explique plus de 60% de la variance")
    print("   ‚Üí Votre mod√®le a une performance satisfaisante")
elif r2 > 0.4:
    print("   ‚ö†Ô∏è MOYEN: Le mod√®le explique plus de 40% de la variance")
    print("   ‚Üí Performance acceptable mais il y a place √† l'am√©lioration")
else:
    print("   ‚ùå FAIBLE: Le mod√®le explique moins de 40% de la variance")
    print("   ‚Üí Le mod√®le n√©cessite des am√©liorations")

# Contexte sp√©cifique aux z-scores
print(f"\nüìã CONTEXTE SP√âCIFIQUE AUX Z-SCORES:")
print(f"   ‚Ä¢ Pour vos donn√©es de z-scores (plage: -442 √† +468):")
print(f"     - Un RMSE < 50 est excellent")
print(f"     - Un RMSE entre 50-100 est acceptable")
print(f"     - Un RMSE > 100 n√©cessite attention")

if rmse < 50:
    print(f"   ‚úÖ Votre RMSE de {rmse:.3f} est EXCELLENT")
elif rmse < 100:
    print(f"   ‚úÖ Votre RMSE de {rmse:.3f} est ACCEPTABLE")
else:
    print(f"   ‚ö†Ô∏è Votre RMSE de {rmse:.3f} n√©cessite attention")

# Ajuster la zone de tol√©rance pour cette √©chelle
tolerance_adjusted = 50  # Tol√©rance adapt√©e √† l'√©chelle r√©elle
within_tolerance_adjusted = np.sum(abs_errors <= tolerance_adjusted)
percentage_within_tolerance_adjusted = (within_tolerance_adjusted / len(errors)) * 100

print(f"\nüéØ PR√âDICTIONS DANS LA ZONE DE TOL√âRANCE ADAPT√âE (¬±{tolerance_adjusted}):")
print(f"   ‚Ä¢ {within_tolerance_adjusted}/{len(errors)} pr√©dictions ({percentage_within_tolerance_adjusted:.1f}%)")

# Analyse de la distribution des z-scores
print(f"\nüìä ANALYSE DE LA DISTRIBUTION DES Z-SCORES:")
print(f"   ‚Ä¢ Z-score minimum: {np.min(y_val_array):.1f}")
print(f"   ‚Ä¢ Z-score maximum: {np.max(y_val_array):.1f}")
print(f"   ‚Ä¢ Z-score moyen: {np.mean(y_val_array):.1f}")
print(f"   ‚Ä¢ √âcart-type des z-scores: {np.std(y_val_array):.1f}")

# Interpr√©tation adapt√©e au contexte
print(f"\nüîç INTERPR√âTATION ADAPT√âE AU CONTEXTE:")
print(f"   ‚Ä¢ Vos z-scores ont une plage tr√®s large ({np.max(y_val_array) - np.min(y_val_array):.1f} unit√©s)")
print(f"   ‚Ä¢ Cette variabilit√© importante rend la pr√©diction plus difficile")
print(f"   ‚Ä¢ Un R¬≤ de {r2:.3f} dans ce contexte est {'excellent' if r2 > 0.6 else 'acceptable' if r2 > 0.4 else '√† am√©liorer'}")

print("="*60)

# Analyse globale du mod√®le
print("\n********************************************")
print("PERFORMANCE GLOBALE DU MOD√àLE")
print("********************************************")
mse = mean_squared_error(y_val_array, y_pred)
r2 = r2_score(y_val_array, y_pred)
print(f"MSE (Erreur quadratique moyenne): {mse:.4f}")
print(f"R¬≤ (Coefficient de d√©termination): {r2:.4f}")
print(f"RMSE (Racine de l'erreur quadratique moyenne): {np.sqrt(mse):.4f}")

# Interpr√©tation de la performance
print("\nInterpr√©tation:")
if r2 > 0.8:
    print("- Le mod√®le a une TR√àS BONNE performance explicative")
elif r2 > 0.6:
    print("- Le mod√®le a une BONNE performance explicative")
elif r2 > 0.4:
    print("- Le mod√®le a une performance explicative MOYENNE")
else:
    print("- Le mod√®le a une performance explicative FAIBLE")

print(f"- Le mod√®le explique {r2*100:.1f}% de la variance dans les donn√©es")
print(f"- En moyenne, les pr√©dictions ont une erreur de {np.sqrt(mse):.4f} unit√©s")

# Apr√®s les visualisations, ajoutons l'analyse des effets
print("\n" + "="*80)
print("ANALYSE LOGIQUE DES EFFETS DES FEATURES SUR LE Z-SCORE")
print("="*80)

print("\nüßÆ APPROCHE SIMPLIFI√âE ET LOGIQUE:")
print("   ‚Ä¢ Analyser les vraies relations entre features et z-score")
print("   ‚Ä¢ Exclure les variables constantes (comme 'time')")
print("   ‚Ä¢ Utiliser des m√©thodes statistiques classiques")

# Analyser les donn√©es d'abord
print(f"\nüìä ANALYSE DES DONN√âES:")
print(f"   ‚Ä¢ Nombre total d'observations: {len(data)}")
print(f"   ‚Ä¢ Features disponibles: {list(data.columns)}")

# Identifier les variables constantes
constant_features = []
for col in data.columns:
    if col != 'zscore':
        unique_values = data[col].nunique()
        if unique_values == 1:
            constant_features.append(col)
            print(f"   ‚ö†Ô∏è Variable constante d√©tect√©e: {col} (valeur: {data[col].iloc[0]})")

if constant_features:
    print(f"\n‚ùå Variables √† exclure (constantes): {constant_features}")
else:
    print(f"\n‚úÖ Aucune variable constante d√©tect√©e")

# Analyser les vraies relations
print(f"\n" + "="*80)
print("ANALYSE DES RELATIONS FEATURE-ZSCORE")
print("="*80)

# Exclure les variables constantes et le target
features_to_analyze = [col for col in data.columns if col not in constant_features + ['zscore']]

print(f"\nüîç Features √† analyser: {features_to_analyze}")

# Analyse de corr√©lation simple
print(f"\nüìà ANALYSE DE CORR√âLATION AVEC LE Z-SCORE:")
correlations = {}
for feature in features_to_analyze:
    correlation = data[feature].corr(data['zscore'])
    correlations[feature] = correlation
    print(f"   ‚Ä¢ {feature}: {correlation:.4f}")

# Trier par importance (valeur absolue de la corr√©lation)
sorted_features = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)

print(f"\nüéØ CLASSEMENT PAR IMPORTANCE (corr√©lation avec z-score):")
for i, (feature, corr) in enumerate(sorted_features, 1):
    direction = "‚Üë" if corr > 0 else "‚Üì"
    strength = "FORT" if abs(corr) > 0.3 else "MOD√âR√â" if abs(corr) > 0.1 else "FAIBLE"
    print(f"   {i}. {feature}: {corr:.4f} {direction} ({strength})")

# Test de significativit√© des corr√©lations
print(f"\nüìä TESTS DE SIGNIFICATIVIT√â:")
significant_features = []
for feature, corr in correlations.items():
    # Test de corr√©lation de Pearson
    from scipy.stats import pearsonr
    correlation, p_value = pearsonr(data[feature], data['zscore'])
    
    if p_value < 0.001:
        significance = "TR√àS SIGNIFICATIF (p < 0.001)"
    elif p_value < 0.01:
        significance = "TR√àS SIGNIFICATIF (p < 0.01)"
    elif p_value < 0.05:
        significance = "SIGNIFICATIF (p < 0.05)"
    else:
        significance = "NON SIGNIFICATIF (p ‚â• 0.05)"
    
    print(f"   ‚Ä¢ {feature}: r={corr:.4f}, p={p_value:.6f} ‚Üí {significance}")
    
    if p_value < 0.05:
        significant_features.append(feature)

print(f"\n‚úÖ FEATURES SIGNIFICATIVES (p < 0.05): {significant_features}")

# Visualisation des relations importantes
print(f"\nüìä G√âN√âRATION DES VISUALISATIONS:")
n_significant = len(significant_features)
if n_significant > 0:
    n_cols = min(3, n_significant)
    n_rows = (n_significant + n_cols - 1) // n_cols
    
    plt.figure(figsize=(5*n_cols, 4*n_rows))
    for i, feature in enumerate(significant_features, 1):
        plt.subplot(n_rows, n_cols, i)
        plt.scatter(data[feature], data['zscore'], alpha=0.6, s=20)
        
        # Ligne de r√©gression
        z = np.polyfit(data[feature], data['zscore'], 1)
        p = np.poly1d(z)
        plt.plot(data[feature], p(data[feature]), "r--", alpha=0.8)
        
        plt.xlabel(feature)
        plt.ylabel('z-score')
        plt.title(f'{feature} vs z-score\nr={correlations[feature]:.3f}')
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('visualisations/correlations_significatives.png', dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   ‚úÖ Graphiques sauvegard√©s dans 'visualisations/correlations_significatives.png'")

# R√©sum√© final logique
print(f"\n" + "="*80)
print("R√âSUM√â LOGIQUE POUR LA PR√âDICTION")
print("="*80)

print(f"\nüéØ FEATURES IMPORTANTES POUR PR√âDIRE LE Z-SCORE:")
if significant_features:
    print(f"   ‚Ä¢ Features avec corr√©lation significative: {', '.join(significant_features)}")
    print(f"   ‚Ä¢ Ces features ont une relation statistiquement prouv√©e avec le z-score")
else:
    print(f"   ‚Ä¢ Aucune feature n'a de corr√©lation significative avec le z-score")

print(f"\nüí° RECOMMANDATIONS:")
print(f"   ‚Ä¢ Concentrez-vous sur les features significatives pour la pr√©diction")
print(f"   ‚Ä¢ Les variables constantes (comme 'time') n'apportent aucune information")
print(f"   ‚Ä¢ Utilisez les corr√©lations pour comprendre les relations lin√©aires")
print(f"   ‚Ä¢ NAMLSS capture les relations non-lin√©aires suppl√©mentaires")

print("="*80)

